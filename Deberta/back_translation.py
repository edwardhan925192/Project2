# -*- coding: utf-8 -*-
"""Back_translation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lc_dj2Qhnfed_ywzrdmWb1lm0w3L_1LJ
"""

from transformers import MarianMTModel, MarianTokenizer

def back_translate(sentence, source_lang='en', target_lang='de'):
    # Specify the translation models to use
    model_name_frwrd = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'
    model_name_back = f'Helsinki-NLP/opus-mt-{target_lang}-{source_lang}'

    # Load the tokenizers and models
    tokenizer_frwrd = MarianTokenizer.from_pretrained(model_name_frwrd)
    model_frwrd = MarianMTModel.from_pretrained(model_name_frwrd)
    tokenizer_back = MarianTokenizer.from_pretrained(model_name_back)
    model_back = MarianMTModel.from_pretrained(model_name_back)

    # Translate to the target language
    tokenized_text = tokenizer_frwrd.encode(sentence, return_tensors='pt')
    translation = model_frwrd.generate(tokenized_text, max_length=len(sentence)+10, num_beams=4, early_stopping=True)
    translated_sentence = tokenizer_frwrd.decode(translation[0], skip_special_tokens=True)

    # Translate back to the source language
    tokenized_text = tokenizer_back.encode(translated_sentence, return_tensors='pt')
    back_translation = model_back.generate(tokenized_text, max_length=len(sentence)+10, num_beams=4, early_stopping=True)
    back_translated_sentence = tokenizer_back.decode(back_translation[0], skip_special_tokens=True)

    return back_translated_sentence

sentence = "The court has decided in favor of the plaintiff."
back_translated_sentence = back_translate(sentence)
print(back_translated_sentence)